{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_pois(cell_size):\n",
    "    \"\"\"\n",
    "    Input: cell_size\n",
    "    Output: (list of pois, labels)\n",
    "    Description: each poi is a identified by a list of features that you find in labels\n",
    "    \"\"\"\n",
    "    base_path = '../../data/w2v_urban/Foursquare/Manhattan/foursquare_Manhattan_'\n",
    "    pois_list_path = base_path + str(cell_size) + \".csv\"\n",
    "    \n",
    "    # fill pois list\n",
    "    pois = []\n",
    "    with open(pois_list_path,  encoding=\"utf8\") as csvfile:\n",
    "        pois_reader = csv.reader(csvfile, delimiter=',')\n",
    "        # do not read the first element of each row\n",
    "        # unamed ?\n",
    "        for i, row in enumerate(pois_reader):\n",
    "            if i == 0:\n",
    "                labels = row[1:]\n",
    "            else:\n",
    "                pois.append(row[1:])\n",
    "    \n",
    "    return pois, labels\n",
    "\n",
    "def load_cells(cell_size):\n",
    "    \"\"\"\n",
    "    Input: cell_size\n",
    "    Output: list of cells\n",
    "    Description: each cells is a dictionary containing keys: cell_id, predominant_class, data_type\n",
    "    data_type = 0 if is part of training set, 1 otherwise\n",
    "    \"\"\"\n",
    "    test_predominant_per_cell = '../../data/w2v_urban/test_classifier/test_Manhattan/' + str(cell_size) + '.csv'\n",
    "    training_predominant_per_cell = '../../data/w2v_urban/train_classifier/train_Manhattan/' + str(cell_size) + '.csv'\n",
    "    \n",
    "    cells = []\n",
    "    for f, file_path in enumerate([training_predominant_per_cell, test_predominant_per_cell]):\n",
    "        with open(file_path) as csvfile:\n",
    "            pois_reader = csv.reader(csvfile, delimiter='\\t')\n",
    "            for i, row in enumerate(pois_reader):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    cell_id = int(row[0])\n",
    "                    predominant_class = row[-1]\n",
    "                    cells.append({'cell_id': cell_id, 'predominant_class': predominant_class, 'data_type': f})\n",
    "    \n",
    "    return cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16132/16132 [06:37<00:00, 40.57it/s]\n",
      "100%|██████████| 5223/5223 [02:02<00:00, 42.48it/s]\n",
      "100%|██████████| 1502/1502 [00:39<00:00, 37.56it/s]\n",
      "100%|██████████| 1005/1005 [00:25<00:00, 40.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "cell_sizes = ['50', '100', '200', '250']\n",
    "for cell_size in cell_sizes:\n",
    "    pois, _ = load_pois(cell_size)\n",
    "    cells = load_cells(cell_size)\n",
    "    \n",
    "    # remove pois without any category\n",
    "    pois = [poi for poi in pois if len(poi[3]) > 0]\n",
    "    \n",
    "    # extract categories\n",
    "    categories = [poi[3].replace(' ', '_').split(':')[-1] for poi in pois]\n",
    "    \n",
    "    # remove duplicates\n",
    "    most_detailed_categories = list(set(categories))\n",
    "    \n",
    "    training_cells_count = []\n",
    "    test_cells_count = []\n",
    "    for cell in tqdm(cells):\n",
    "        cell_id = cell['cell_id']\n",
    "        predominant_class = cell['predominant_class']\n",
    "        cell_pois = [poi for poi in pois if poi[-1] == str(cell_id)]\n",
    "        cell_pois_category = [poi[3].replace(' ', '_').split(':')[-1] for poi in cell_pois]\n",
    "        cell_count = dict(Counter(cell_pois_category))\n",
    "        counter_array = [cell_count[category] if category in cell_count else 0 for category in most_detailed_categories]\n",
    "        if cell['data_type'] == 0:\n",
    "            training_cells_count.append([cell_id] + counter_array + [predominant_class])\n",
    "        else:\n",
    "            test_cells_count.append([cell_id] + counter_array + [predominant_class])\n",
    "            \n",
    "    # write on files\n",
    "    # training\n",
    "    folder = '../../data/w2v_urban/mdetail/baseline/'\n",
    "    with open(folder + 'training' + str(cell_size) + '.csv', 'w', newline='') as csvfile:\n",
    "        datawriter = csv.writer(csvfile, delimiter='\\t')\n",
    "        datawriter.writerow(['cellID'] + most_detailed_categories + ['t_predominant'])\n",
    "        for count_array in training_cells_count:\n",
    "            datawriter.writerow(count_array)\n",
    "            \n",
    "    # training\n",
    "    with open(folder + 'test' + str(cell_size) + '.csv', 'w', newline='') as csvfile:\n",
    "        datawriter = csv.writer(csvfile, delimiter='\\t')\n",
    "        datawriter.writerow(['cellID'] + most_detailed_categories + ['t_predominant'])\n",
    "        for count_array in test_cells_count:\n",
    "            datawriter.writerow(count_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
